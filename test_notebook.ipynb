{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "533e8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/workspaces/parameta-data-science-test/Parameta/stdev_test/results/rolling_std_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9021e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_checker = df[(df['security_id'] == 'id_44') & (df['snap_time'] >= '2021-11-20 00:00:00')].sort_values(by='snap_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f8261603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snap_time</th>\n",
       "      <th>security_id</th>\n",
       "      <th>bid_std</th>\n",
       "      <th>mid_std</th>\n",
       "      <th>ask_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90683</th>\n",
       "      <td>2021-11-20 00:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.135613e+00</td>\n",
       "      <td>1.135714e+00</td>\n",
       "      <td>1.135816e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90882</th>\n",
       "      <td>2021-11-20 01:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.076226e+00</td>\n",
       "      <td>1.076340e+00</td>\n",
       "      <td>1.076454e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91081</th>\n",
       "      <td>2021-11-20 02:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.007814e+00</td>\n",
       "      <td>1.007943e+00</td>\n",
       "      <td>1.008073e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91280</th>\n",
       "      <td>2021-11-20 03:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>9.283843e-01</td>\n",
       "      <td>9.285327e-01</td>\n",
       "      <td>9.286823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91479</th>\n",
       "      <td>2021-11-20 04:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>8.237706e-01</td>\n",
       "      <td>8.237002e-01</td>\n",
       "      <td>8.236308e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91678</th>\n",
       "      <td>2021-11-20 05:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>8.108593e-01</td>\n",
       "      <td>8.107387e-01</td>\n",
       "      <td>8.106192e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91877</th>\n",
       "      <td>2021-11-20 06:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>8.157980e-01</td>\n",
       "      <td>8.156821e-01</td>\n",
       "      <td>8.155672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92076</th>\n",
       "      <td>2021-11-20 07:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>8.177406e-01</td>\n",
       "      <td>8.176291e-01</td>\n",
       "      <td>8.175185e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92275</th>\n",
       "      <td>2021-11-20 08:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>7.455657e-01</td>\n",
       "      <td>7.453472e-01</td>\n",
       "      <td>7.451298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92474</th>\n",
       "      <td>2021-11-20 09:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>5.505545e-01</td>\n",
       "      <td>5.507022e-01</td>\n",
       "      <td>5.508508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92673</th>\n",
       "      <td>2021-11-20 10:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>2.384277e-01</td>\n",
       "      <td>2.388428e-01</td>\n",
       "      <td>2.392595e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92872</th>\n",
       "      <td>2021-11-20 11:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>2.001432e-01</td>\n",
       "      <td>2.004646e-01</td>\n",
       "      <td>2.007878e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93071</th>\n",
       "      <td>2021-11-20 12:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>4.069644e-02</td>\n",
       "      <td>4.136726e-02</td>\n",
       "      <td>4.203808e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93270</th>\n",
       "      <td>2021-11-20 13:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93469</th>\n",
       "      <td>2021-11-20 14:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93668</th>\n",
       "      <td>2021-11-20 15:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93867</th>\n",
       "      <td>2021-11-20 16:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94066</th>\n",
       "      <td>2021-11-20 17:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94265</th>\n",
       "      <td>2021-11-20 18:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94464</th>\n",
       "      <td>2021-11-20 19:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94663</th>\n",
       "      <td>2021-11-20 20:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94862</th>\n",
       "      <td>2021-11-20 21:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95061</th>\n",
       "      <td>2021-11-20 22:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95260</th>\n",
       "      <td>2021-11-20 23:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95459</th>\n",
       "      <td>2021-11-21 00:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95658</th>\n",
       "      <td>2021-11-21 01:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95857</th>\n",
       "      <td>2021-11-21 02:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96056</th>\n",
       "      <td>2021-11-21 03:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96255</th>\n",
       "      <td>2021-11-21 04:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96454</th>\n",
       "      <td>2021-11-21 05:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96653</th>\n",
       "      <td>2021-11-21 06:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96852</th>\n",
       "      <td>2021-11-21 07:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97051</th>\n",
       "      <td>2021-11-21 08:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97250</th>\n",
       "      <td>2021-11-21 09:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97449</th>\n",
       "      <td>2021-11-21 10:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97648</th>\n",
       "      <td>2021-11-21 11:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97847</th>\n",
       "      <td>2021-11-21 12:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98046</th>\n",
       "      <td>2021-11-21 13:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98245</th>\n",
       "      <td>2021-11-21 14:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98444</th>\n",
       "      <td>2021-11-21 15:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98643</th>\n",
       "      <td>2021-11-21 16:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98842</th>\n",
       "      <td>2021-11-21 17:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99041</th>\n",
       "      <td>2021-11-21 18:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99240</th>\n",
       "      <td>2021-11-21 19:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99439</th>\n",
       "      <td>2021-11-21 20:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99638</th>\n",
       "      <td>2021-11-21 21:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99837</th>\n",
       "      <td>2021-11-21 22:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100036</th>\n",
       "      <td>2021-11-21 23:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100235</th>\n",
       "      <td>2021-11-22 00:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100434</th>\n",
       "      <td>2021-11-22 01:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100633</th>\n",
       "      <td>2021-11-22 02:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>2021-11-22 03:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101031</th>\n",
       "      <td>2021-11-22 04:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101230</th>\n",
       "      <td>2021-11-22 05:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101429</th>\n",
       "      <td>2021-11-22 06:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101628</th>\n",
       "      <td>2021-11-22 07:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101827</th>\n",
       "      <td>2021-11-22 08:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102026</th>\n",
       "      <td>2021-11-22 09:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102225</th>\n",
       "      <td>2021-11-22 10:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102424</th>\n",
       "      <td>2021-11-22 11:00:00</td>\n",
       "      <td>id_44</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>1.822504e-15</td>\n",
       "      <td>3.645007e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  snap_time security_id       bid_std       mid_std  \\\n",
       "90683   2021-11-20 00:00:00       id_44  1.135613e+00  1.135714e+00   \n",
       "90882   2021-11-20 01:00:00       id_44  1.076226e+00  1.076340e+00   \n",
       "91081   2021-11-20 02:00:00       id_44  1.007814e+00  1.007943e+00   \n",
       "91280   2021-11-20 03:00:00       id_44  9.283843e-01  9.285327e-01   \n",
       "91479   2021-11-20 04:00:00       id_44  8.237706e-01  8.237002e-01   \n",
       "91678   2021-11-20 05:00:00       id_44  8.108593e-01  8.107387e-01   \n",
       "91877   2021-11-20 06:00:00       id_44  8.157980e-01  8.156821e-01   \n",
       "92076   2021-11-20 07:00:00       id_44  8.177406e-01  8.176291e-01   \n",
       "92275   2021-11-20 08:00:00       id_44  7.455657e-01  7.453472e-01   \n",
       "92474   2021-11-20 09:00:00       id_44  5.505545e-01  5.507022e-01   \n",
       "92673   2021-11-20 10:00:00       id_44  2.384277e-01  2.388428e-01   \n",
       "92872   2021-11-20 11:00:00       id_44  2.001432e-01  2.004646e-01   \n",
       "93071   2021-11-20 12:00:00       id_44  4.069644e-02  4.136726e-02   \n",
       "93270   2021-11-20 13:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "93469   2021-11-20 14:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "93668   2021-11-20 15:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "93867   2021-11-20 16:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "94066   2021-11-20 17:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "94265   2021-11-20 18:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "94464   2021-11-20 19:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "94663   2021-11-20 20:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "94862   2021-11-20 21:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "95061   2021-11-20 22:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "95260   2021-11-20 23:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "95459   2021-11-21 00:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "95658   2021-11-21 01:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "95857   2021-11-21 02:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "96056   2021-11-21 03:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "96255   2021-11-21 04:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "96454   2021-11-21 05:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "96653   2021-11-21 06:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "96852   2021-11-21 07:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "97051   2021-11-21 08:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "97250   2021-11-21 09:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "97449   2021-11-21 10:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "97648   2021-11-21 11:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "97847   2021-11-21 12:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "98046   2021-11-21 13:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "98245   2021-11-21 14:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "98444   2021-11-21 15:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "98643   2021-11-21 16:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "98842   2021-11-21 17:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "99041   2021-11-21 18:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "99240   2021-11-21 19:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "99439   2021-11-21 20:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "99638   2021-11-21 21:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "99837   2021-11-21 22:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "100036  2021-11-21 23:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "100235  2021-11-22 00:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "100434  2021-11-22 01:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "100633  2021-11-22 02:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "100832  2021-11-22 03:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "101031  2021-11-22 04:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "101230  2021-11-22 05:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "101429  2021-11-22 06:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "101628  2021-11-22 07:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "101827  2021-11-22 08:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "102026  2021-11-22 09:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "102225  2021-11-22 10:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "102424  2021-11-22 11:00:00       id_44  1.822504e-15  1.822504e-15   \n",
       "\n",
       "             ask_std  \n",
       "90683   1.135816e+00  \n",
       "90882   1.076454e+00  \n",
       "91081   1.008073e+00  \n",
       "91280   9.286823e-01  \n",
       "91479   8.236308e-01  \n",
       "91678   8.106192e-01  \n",
       "91877   8.155672e-01  \n",
       "92076   8.175185e-01  \n",
       "92275   7.451298e-01  \n",
       "92474   5.508508e-01  \n",
       "92673   2.392595e-01  \n",
       "92872   2.007878e-01  \n",
       "93071   4.203808e-02  \n",
       "93270   3.645007e-15  \n",
       "93469   3.645007e-15  \n",
       "93668   3.645007e-15  \n",
       "93867   3.645007e-15  \n",
       "94066   3.645007e-15  \n",
       "94265   3.645007e-15  \n",
       "94464   3.645007e-15  \n",
       "94663   3.645007e-15  \n",
       "94862   3.645007e-15  \n",
       "95061   3.645007e-15  \n",
       "95260   3.645007e-15  \n",
       "95459   3.645007e-15  \n",
       "95658   3.645007e-15  \n",
       "95857   3.645007e-15  \n",
       "96056   3.645007e-15  \n",
       "96255   3.645007e-15  \n",
       "96454   3.645007e-15  \n",
       "96653   3.645007e-15  \n",
       "96852   3.645007e-15  \n",
       "97051   3.645007e-15  \n",
       "97250   3.645007e-15  \n",
       "97449   3.645007e-15  \n",
       "97648   3.645007e-15  \n",
       "97847   3.645007e-15  \n",
       "98046   3.645007e-15  \n",
       "98245   3.645007e-15  \n",
       "98444   3.645007e-15  \n",
       "98643   3.645007e-15  \n",
       "98842   3.645007e-15  \n",
       "99041   3.645007e-15  \n",
       "99240   3.645007e-15  \n",
       "99439   3.645007e-15  \n",
       "99638   3.645007e-15  \n",
       "99837   3.645007e-15  \n",
       "100036  3.645007e-15  \n",
       "100235  3.645007e-15  \n",
       "100434  3.645007e-15  \n",
       "100633  3.645007e-15  \n",
       "100832  3.645007e-15  \n",
       "101031  3.645007e-15  \n",
       "101230  3.645007e-15  \n",
       "101429  3.645007e-15  \n",
       "101628  3.645007e-15  \n",
       "101827  3.645007e-15  \n",
       "102026  3.645007e-15  \n",
       "102225  3.645007e-15  \n",
       "102424  3.645007e-15  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_checker.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8bc6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['security_id'] == 'id_44'].sort_values(by='snap_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c14212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: remove two rows for security_id 'ID_44'\n",
    "mask = ~((df['security_id'] == 'id_44') & \n",
    "         (df['snap_time'].isin(pd.to_datetime(['2021-11-20 17:00:00', '2021-11-21 18:00:00']))))\n",
    "df_missing = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d70b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing.to_parquet(\"/workspaces/parameta-data-science-test/Parameta/stdev_test/data/stdev_price_data_missing.parq.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14bb1b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97284, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aafa9579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a38e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.read_parquet(r\"/workspaces/parameta-data-science-test/Parameta/stdev_test/data/stdev_price_data_missing.parq.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0785f254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97284, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0010748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "class RollingStandardDeviationCalculator:\n",
    "    def __init__(self, window_size: int = 20):\n",
    "        self.window_size = window_size\n",
    "        self.price_columns = ['bid', 'mid', 'ask']\n",
    "\n",
    "    def load_data(self, file_path: Path) -> pd.DataFrame:\n",
    "        \"\"\"Load and prepare data\"\"\"\n",
    "        df = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "        df['snap_time'] = pd.to_datetime(df['snap_time'])\n",
    "        return df.sort_values(['security_id', 'snap_time'])\n",
    "\n",
    "    def _find_contiguous_windows(self, values, valid_mask):\n",
    "        \"\"\"\n",
    "        Pre-compute all valid contiguous windows of size >= window_size\n",
    "        Returns dict mapping end_index -> (start_index, end_index, precomputed_std)\n",
    "        \"\"\"\n",
    "        windows = {}\n",
    "        n = len(valid_mask)\n",
    "        \n",
    "        # Find all contiguous sequences\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            if not valid_mask[i]:\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Found start of contiguous sequence\n",
    "            start = i\n",
    "            while i < n and valid_mask[i]:\n",
    "                i += 1\n",
    "            end = i - 1\n",
    "            \n",
    "            # If sequence is long enough, compute rolling std for all positions\n",
    "            seq_length = end - start + 1\n",
    "            if seq_length >= self.window_size:\n",
    "                # Extract the sequence\n",
    "                seq_values = values[start:end+1]\n",
    "                \n",
    "                # Compute rolling std using pandas (vectorized)\n",
    "                seq_df = pd.DataFrame(seq_values, columns=self.price_columns)\n",
    "                rolling_std = seq_df.rolling(self.window_size).std(ddof=1).values\n",
    "                \n",
    "                # Store each valid window\n",
    "                for j in range(self.window_size - 1, seq_length):\n",
    "                    actual_idx = start + j\n",
    "                    windows[actual_idx] = rolling_std[j]\n",
    "        \n",
    "        return windows\n",
    "\n",
    "    def _get_most_recent_std(self, windows, current_idx, sorted_keys=None):\n",
    "        \"\"\"Optimized: use sorted keys + binary search\"\"\"\n",
    "        if not windows:\n",
    "            return np.full(len(self.price_columns), np.nan)\n",
    "        \n",
    "        if sorted_keys is None:\n",
    "            sorted_keys = sorted(windows.keys())\n",
    "        \n",
    "        # Find rightmost key <= current_idx using binary search\n",
    "        import bisect\n",
    "        pos = bisect.bisect_right(sorted_keys, current_idx)\n",
    "        if pos == 0:\n",
    "            return np.full(len(self.price_columns), np.nan)\n",
    "        \n",
    "        best_idx = sorted_keys[pos - 1]\n",
    "        return windows[best_idx]\n",
    "\n",
    "    def calculate_rolling_std(self, df: pd.DataFrame, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Calculate rolling standard deviations with optimized lookback\"\"\"\n",
    "        if start_time:\n",
    "            start_dt = pd.to_datetime(start_time)\n",
    "        else:\n",
    "            start_dt = df['snap_time'].min()\n",
    "\n",
    "        if end_time:\n",
    "            end_dt = pd.to_datetime(end_time)\n",
    "        else:\n",
    "            end_dt = df['snap_time'].max()\n",
    "\n",
    "        # Generate complete time grid\n",
    "        all_snaps = pd.date_range(start=start_dt, end=end_dt, freq='h')\n",
    "        \n",
    "        # Pre-group data by security for efficiency\n",
    "        grouped = df.groupby('security_id')\n",
    "        \n",
    "        # Process all securities at once using vectorized operations\n",
    "        result_data = []\n",
    "        \n",
    "        for sec_id, sec_df in grouped:\n",
    "            # Create complete time series including historical data for lookback\n",
    "            sec_df = sec_df.set_index('snap_time').sort_index()\n",
    "            \n",
    "            # Reindex to hourly grid (this will add NaN for missing snaps)\n",
    "            full_series = sec_df.reindex(all_snaps)\n",
    "            \n",
    "            # Convert to numpy for faster processing\n",
    "            values = full_series[self.price_columns].values\n",
    "            valid_mask = ~np.isnan(values).any(axis=1)\n",
    "            \n",
    "            # Pre-compute all valid rolling std windows\n",
    "            windows = self._find_contiguous_windows(values, valid_mask)\n",
    "            \n",
    "            # Pre-sort keys once for binary search optimization\n",
    "            sorted_keys = sorted(windows.keys()) if windows else []\n",
    "            \n",
    "            # Vectorized lookup for all snap times\n",
    "            result_stds = np.full((len(all_snaps), len(self.price_columns)), np.nan)\n",
    "            \n",
    "            for i in range(len(all_snaps)):\n",
    "                result_stds[i] = self._get_most_recent_std(windows, i, sorted_keys)\n",
    "            \n",
    "            # Create result DataFrame directly (avoid numpy dtype mixing)\n",
    "            sec_result_data = {\n",
    "                'snap_time': all_snaps,\n",
    "                'security_id': sec_id\n",
    "            }\n",
    "            \n",
    "            # Add std columns\n",
    "            for j, col in enumerate(self.price_columns):\n",
    "                sec_result_data[f\"{col}_std\"] = result_stds[:, j]\n",
    "            \n",
    "            sec_result = pd.DataFrame(sec_result_data)\n",
    "            result_data.append(sec_result)\n",
    "        \n",
    "        if result_data:\n",
    "            # Combine all securities using pandas concat\n",
    "            results = pd.concat(result_data, ignore_index=True)\n",
    "            \n",
    "            # Sort final results\n",
    "            results = results.sort_values(['snap_time', 'security_id']).reset_index(drop=True)\n",
    "        else:\n",
    "            # Empty result\n",
    "            columns = ['snap_time', 'security_id'] + [f\"{c}_std\" for c in self.price_columns]\n",
    "            results = pd.DataFrame(columns=columns)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_results(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        \"\"\"Save results to CSV file\"\"\"\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        results_df_output = results_df.copy()\n",
    "        results_df_output['snap_time'] = results_df_output['snap_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        results_df_output.to_csv(output_path, index=False)\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "    def process_file(self, input_file: Path, output_file: Path, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Full processing pipeline\"\"\"\n",
    "        start_processing = time.time()\n",
    "        \n",
    "        print(f\"Loading data from: {input_file}\")\n",
    "        df = self.load_data(input_file)\n",
    "        print(f\"Loaded {len(df):,} rows\")\n",
    "        \n",
    "        print(\"Calculating rolling standard deviations...\")\n",
    "        results = self.calculate_rolling_std(df, start_time, end_time)\n",
    "        print(f\"Generated {len(results):,} result rows\")\n",
    "        \n",
    "        self.save_results(results, output_file)\n",
    "        \n",
    "        processing_time = time.time() - start_processing\n",
    "        print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Calculate rolling standard deviation with lookback\")\n",
    "    \n",
    "    default_input = Path(__file__).parent.parent / \"data\" / \"stdev_price_data.parq\"\n",
    "    default_output = Path(__file__).parent.parent / \"results\" / \"rolling_std_results.csv\"\n",
    "\n",
    "    parser.add_argument(\"--input\", type=str, default=default_input, \n",
    "                       help=\"Path to input parquet file\")\n",
    "    parser.add_argument(\"--output\", type=str, default=default_output, \n",
    "                       help=\"Path to output CSV file\")\n",
    "    parser.add_argument(\"--start_time\", type=str, \n",
    "                       help=\"Start time (YYYY-MM-DD HH:MM:SS)\")\n",
    "    parser.add_argument(\"--end_time\", type=str, \n",
    "                       help=\"End time (YYYY-MM-DD HH:MM:SS)\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    calculator = RollingStandardDeviationCalculator(window_size=20)\n",
    "    calculator.process_file(\n",
    "        input_file=Path(args.input),\n",
    "        output_file=Path(args.output),\n",
    "        start_time=args.start_time,\n",
    "        end_time=args.end_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7391f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "class RollingStandardDeviationCalculator:\n",
    "    def __init__(self, window_size: int = 20):\n",
    "        self.window_size = window_size\n",
    "        self.price_columns = ['bid', 'mid', 'ask']\n",
    "\n",
    "    def load_data(self, file_path: Path) -> pd.DataFrame:\n",
    "        df = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "        df['snap_time'] = pd.to_datetime(df['snap_time'])\n",
    "        return df.sort_values(['security_id', 'snap_time'])\n",
    "\n",
    "    def calculate_rolling_std(self, df: pd.DataFrame, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        if start_time:\n",
    "            start_dt = pd.to_datetime(start_time)\n",
    "        else:\n",
    "            start_dt = df['snap_time'].min()\n",
    "        if end_time:\n",
    "            end_dt = pd.to_datetime(end_time)\n",
    "        else:\n",
    "            end_dt = df['snap_time'].max()\n",
    "\n",
    "        # Generate output hourly range\n",
    "        output_snaps = pd.date_range(start=start_dt, end=end_dt, freq='h')\n",
    "        grouped = df.groupby('security_id')\n",
    "        result_data = []\n",
    "\n",
    "        for sec_id, sec_df in grouped:\n",
    "            sec_df = sec_df.set_index('snap_time').sort_index()\n",
    "            # Reindex only once from earliest data to end_dt\n",
    "            full_range = pd.date_range(start=sec_df.index.min(), end=end_dt, freq='h')\n",
    "            full_df = sec_df.reindex(full_range)\n",
    "            values = full_df[self.price_columns].values  # shape (n_timestamps, 3)\n",
    "\n",
    "            # Mask for valid rows (no NaNs)\n",
    "            valid_mask = ~np.isnan(values).any(axis=1)\n",
    "\n",
    "            # Precompute rolling std only on valid rows using a sliding window\n",
    "            n_rows = values.shape[0]\n",
    "            rolling_std = np.full_like(values, np.nan, dtype=float)\n",
    "\n",
    "            # Use a deque for a fast sliding window of 20 valid values\n",
    "            from collections import deque\n",
    "            window = deque(maxlen=self.window_size)\n",
    "\n",
    "            for i in range(n_rows):\n",
    "                if valid_mask[i]:\n",
    "                    window.append(values[i])\n",
    "                if len(window) == self.window_size:\n",
    "                    rolling_std[i] = np.std(np.array(window), axis=0, ddof=1)\n",
    "\n",
    "            # Map results to output snaps\n",
    "            idx_map = full_range.get_indexer(output_snaps)\n",
    "            output_std = rolling_std[idx_map]\n",
    "\n",
    "            # Build result DataFrame\n",
    "            sec_result = pd.DataFrame({\n",
    "                'snap_time': output_snaps,\n",
    "                'security_id': sec_id,\n",
    "                'bid_std': output_std[:, 0],\n",
    "                'mid_std': output_std[:, 1],\n",
    "                'ask_std': output_std[:, 2]\n",
    "            })\n",
    "\n",
    "            result_data.append(sec_result)\n",
    "\n",
    "        results = pd.concat(result_data, ignore_index=True)\n",
    "        results.sort_values(['snap_time', 'security_id'], inplace=True)\n",
    "        results.reset_index(drop=True, inplace=True)\n",
    "        return results\n",
    "\n",
    "    def save_results(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        results_df_output = results_df.copy()\n",
    "        results_df_output['snap_time'] = results_df_output['snap_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        results_df_output.to_csv(output_path, index=False)\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "    def process_file(self, input_file: Path, output_file: Path, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        start_processing = time.time()\n",
    "        df = self.load_data(input_file)\n",
    "        results = self.calculate_rolling_std(df, start_time, end_time)\n",
    "        self.save_results(results, output_file)\n",
    "        print(f\"Total processing time: {time.time() - start_processing:.2f} seconds\")\n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Calculate rolling standard deviation with lookback\")\n",
    "    default_input = Path(__file__).parent.parent / \"data\" / \"stdev_price_data.parq\"\n",
    "    default_output = Path(__file__).parent.parent / \"results\" / \"rolling_std_results.csv\"\n",
    "\n",
    "    parser.add_argument(\"--input\", type=str, default=default_input)\n",
    "    parser.add_argument(\"--output\", type=str, default=default_output)\n",
    "    parser.add_argument(\"--start_time\", type=str)\n",
    "    parser.add_argument(\"--end_time\", type=str)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    calculator = RollingStandardDeviationCalculator(window_size=20)\n",
    "    calculator.process_file(\n",
    "        input_file=Path(args.input),\n",
    "        output_file=Path(args.output),\n",
    "        start_time=args.start_time,\n",
    "        end_time=args.end_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "082d0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfect version with starting trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "class RollingStandardDeviationCalculator:\n",
    "    def __init__(self, window_size: int = 20):\n",
    "        self.window_size = window_size\n",
    "        self.price_columns = ['bid', 'mid', 'ask']\n",
    "\n",
    "    def load_data(self, file_path: Path) -> pd.DataFrame:\n",
    "        df = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "        df['snap_time'] = pd.to_datetime(df['snap_time'])\n",
    "        return df.sort_values(['security_id', 'snap_time'])\n",
    "\n",
    "    def calculate_rolling_std(self, df: pd.DataFrame, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        if start_time:\n",
    "            start_dt = pd.to_datetime(start_time)\n",
    "        else:\n",
    "            start_dt = df['snap_time'].min()\n",
    "        if end_time:\n",
    "            end_dt = pd.to_datetime(end_time)\n",
    "        else:\n",
    "            end_dt = df['snap_time'].max()\n",
    "\n",
    "        # Generate output hourly range for the REQUESTED period\n",
    "        output_snaps = pd.date_range(start=start_dt, end=end_dt, freq='h')\n",
    "        \n",
    "        # Get all unique security IDs in the dataset\n",
    "        all_security_ids = df['security_id'].unique()\n",
    "        \n",
    "        # Create a complete cross-product of all security_ids and all output snap times\n",
    "        result_data = []\n",
    "\n",
    "        for sec_id in all_security_ids:\n",
    "            sec_df = df[df['security_id'] == sec_id].copy()\n",
    "            \n",
    "            if len(sec_df) == 0:\n",
    "                # If no data for this security, create all NaN results\n",
    "                sec_result = pd.DataFrame({\n",
    "                    'snap_time': output_snaps,\n",
    "                    'security_id': sec_id,\n",
    "                    'bid_std': np.nan,\n",
    "                    'mid_std': np.nan,\n",
    "                    'ask_std': np.nan\n",
    "                })\n",
    "                result_data.append(sec_result)\n",
    "                continue\n",
    "            \n",
    "            sec_df = sec_df.set_index('snap_time').sort_index()\n",
    "            \n",
    "            # Reindex to cover the full range needed for lookback calculation\n",
    "            # We need to go back far enough to potentially find 20 contiguous values\n",
    "            earliest_data = sec_df.index.min()\n",
    "            lookback_start = min(earliest_data, start_dt - pd.Timedelta(hours=self.window_size))\n",
    "            \n",
    "            # Create full range from lookback_start to end_dt\n",
    "            full_range = pd.date_range(start=lookback_start, end=end_dt, freq='h')\n",
    "            full_df = sec_df.reindex(full_range)\n",
    "            values = full_df[self.price_columns].values  # shape (n_timestamps, 3)\n",
    "\n",
    "            n_rows = values.shape[0]\n",
    "            rolling_std = np.full((n_rows, 3), np.nan, dtype=float)\n",
    "\n",
    "            # Track the rolling window and the most recent valid calculation\n",
    "            current_window = []\n",
    "            last_valid_window = None\n",
    "            last_valid_std = None\n",
    "            \n",
    "            for i in range(n_rows):\n",
    "                row = values[i]\n",
    "                \n",
    "                if np.isnan(row).any():\n",
    "                    # Missing data - reset current window but keep using last valid std\n",
    "                    current_window = []\n",
    "                    if last_valid_std is not None:\n",
    "                        rolling_std[i] = last_valid_std\n",
    "                else:\n",
    "                    # Valid data - add to current window\n",
    "                    current_window.append(row)\n",
    "                    \n",
    "                    # Keep only the last window_size values\n",
    "                    if len(current_window) > self.window_size:\n",
    "                        current_window.pop(0)\n",
    "                    \n",
    "                    if len(current_window) == self.window_size:\n",
    "                        # We have a new complete window of 20 contiguous values\n",
    "                        last_valid_window = current_window.copy()\n",
    "                        last_valid_std = np.std(np.array(last_valid_window), axis=0, ddof=1)\n",
    "                        rolling_std[i] = last_valid_std\n",
    "                    elif last_valid_std is not None:\n",
    "                        # Still building new window, but use last valid std\n",
    "                        rolling_std[i] = last_valid_std\n",
    "\n",
    "            # Map results to the requested output snaps ONLY\n",
    "            idx_map = full_range.get_indexer(output_snaps)\n",
    "            output_std = rolling_std[idx_map]\n",
    "\n",
    "            sec_result = pd.DataFrame({\n",
    "                'snap_time': output_snaps,\n",
    "                'security_id': sec_id,\n",
    "                'bid_std': output_std[:, 0],\n",
    "                'mid_std': output_std[:, 1],\n",
    "                'ask_std': output_std[:, 2]\n",
    "            })\n",
    "            result_data.append(sec_result)\n",
    "\n",
    "        results = pd.concat(result_data, ignore_index=True)\n",
    "        results = results.sort_values(['snap_time', 'security_id']).reset_index(drop=True)\n",
    "        return results\n",
    "\n",
    "    def save_results(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        results_df_output = results_df.copy()\n",
    "        results_df_output['snap_time'] = results_df_output['snap_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        results_df_output.to_csv(output_path, index=False)\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "    def process_file(self, input_file: Path, output_file: Path, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        start_processing = time.time()\n",
    "        df = self.load_data(input_file)\n",
    "        results = self.calculate_rolling_std(df, start_time, end_time)\n",
    "        self.save_results(results, output_file)\n",
    "        print(f\"Total processing time: {time.time() - start_processing:.2f} seconds\")\n",
    "        print(f\"Output shape: {results.shape}\")\n",
    "        print(f\"Unique security IDs: {results['security_id'].nunique()}\")\n",
    "        print(f\"Time range: {results['snap_time'].min()} to {results['snap_time'].max()}\")\n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Calculate rolling standard deviation with lookback\")\n",
    "    default_input = Path(__file__).parent.parent / \"data\" / \"stdev_price_data.parq\"\n",
    "    default_output = Path(__file__).parent.parent / \"results\" / \"rolling_std_results.csv\"\n",
    "\n",
    "    parser.add_argument(\"--input\", type=str, default=default_input)\n",
    "    parser.add_argument(\"--output\", type=str, default=default_output)\n",
    "    parser.add_argument(\"--start_time\", type=str, default=\"2021-11-20 00:00:00\")\n",
    "    parser.add_argument(\"--end_time\", type=str, default=\"2021-11-23 09:00:00\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    calculator = RollingStandardDeviationCalculator(window_size=20)\n",
    "    calculator.process_file(\n",
    "        input_file=Path(args.input),\n",
    "        output_file=Path(args.output),\n",
    "        start_time=args.start_time,\n",
    "        end_time=args.end_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class CalculationConfig:\n",
    "    window_size: int = 20\n",
    "    price_columns: List[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.price_columns is None:\n",
    "            self.price_columns = ['bid', 'mid', 'ask']\n",
    "\n",
    "class RollingStandardDeviationCalculator:\n",
    "    def __init__(self, window_size: int = 20):\n",
    "        self.config = CalculationConfig(window_size=window_size)\n",
    "\n",
    "    def load_data(self, file_path: Path) -> pd.DataFrame:\n",
    "        \"\"\"Load and prepare data with optimized dtypes\"\"\"\n",
    "        df = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "        df['snap_time'] = pd.to_datetime(df['snap_time'])\n",
    "        return df.sort_values(['security_id', 'snap_time'])\n",
    "\n",
    "    def _vectorized_rolling_std_single_security(self, sec_df: pd.DataFrame, output_snaps: pd.DatetimeIndex) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fully vectorized rolling std calculation using pandas rolling + forward fill\n",
    "        \"\"\"\n",
    "        # Align index to full hourly range\n",
    "        sec_df = sec_df.set_index('snap_time').sort_index().asfreq('H')\n",
    "        \n",
    "        # Calculate rolling std using pandas (C-optimized)\n",
    "        rolling_std = sec_df[self.config.price_columns].rolling(\n",
    "            window=self.config.window_size, min_periods=self.config.window_size\n",
    "        ).std(ddof=1)\n",
    "        \n",
    "        # Forward fill last valid std to mimic your last_valid_std logic\n",
    "        rolling_std = rolling_std.ffill()\n",
    "        \n",
    "        # Reindex to output snapshots\n",
    "        rolling_std = rolling_std.reindex(output_snaps)\n",
    "        \n",
    "        return rolling_std\n",
    "\n",
    "    def calculate_rolling_std(self, df: pd.DataFrame, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Optimized calculation using vectorized operations\"\"\"\n",
    "        if start_time:\n",
    "            start_dt = pd.to_datetime(start_time)\n",
    "        else:\n",
    "            start_dt = df['snap_time'].min()\n",
    "        if end_time:\n",
    "            end_dt = pd.to_datetime(end_time)\n",
    "        else:\n",
    "            end_dt = df['snap_time'].max()\n",
    "\n",
    "        output_snaps = pd.date_range(start=start_dt, end=end_dt, freq='h')\n",
    "        grouped = df.groupby('security_id', sort=False)\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for sec_id, sec_df in grouped:\n",
    "            sec_std = self._vectorized_rolling_std_single_security(sec_df, output_snaps)\n",
    "            sec_std['security_id'] = sec_id\n",
    "            sec_std['snap_time'] = sec_std.index\n",
    "            result_list.append(sec_std.reset_index(drop=True))\n",
    "\n",
    "        results = pd.concat(result_list, ignore_index=True)\n",
    "        results = results[['snap_time', 'security_id'] + self.config.price_columns]\n",
    "        results.columns = ['snap_time', 'security_id', 'bid_std', 'mid_std', 'ask_std']\n",
    "        \n",
    "        return results.sort_values(['snap_time', 'security_id']).reset_index(drop=True)\n",
    "\n",
    "    def save_results(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        \"\"\"Save results efficiently\"\"\"\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Convert snap_time to string in vectorized manner\n",
    "        results_df['snap_time'] = results_df['snap_time'].astype(str)\n",
    "        results_df.to_csv(output_path, index=False)\n",
    "        print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "    def process_file(self, input_file: Path, output_file: Path, start_time: str = None, end_time: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Main processing pipeline with timing\"\"\"\n",
    "        start_processing = time.time()\n",
    "        \n",
    "        df = self.load_data(input_file)\n",
    "        results = self.calculate_rolling_std(df, start_time, end_time)\n",
    "        self.save_results(results, output_file)\n",
    "        \n",
    "        processing_time = time.time() - start_processing\n",
    "        print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
    "        print(f\"Output shape: {results.shape}\")\n",
    "        print(f\"Unique security IDs: {results['security_id'].nunique()}\")\n",
    "        print(f\"Time range: {results['snap_time'].min()} to {results['snap_time'].max()}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Calculate rolling standard deviation with lookback\")\n",
    "    default_input = Path(__file__).parent.parent / \"data\" / \"stdev_price_data.parq\"\n",
    "    default_output = Path(__file__).parent.parent / \"results\" / \"rolling_std_results.csv\"\n",
    "\n",
    "    parser.add_argument(\"--input\", type=str, default=default_input)\n",
    "    parser.add_argument(\"--output\", type=str, default=default_output)\n",
    "    parser.add_argument(\"--start_time\", type=str, default=\"2021-11-20 00:00:00\")\n",
    "    parser.add_argument(\"--end_time\", type=str, default=\"2021-11-23 09:00:00\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    calculator = RollingStandardDeviationCalculator(window_size=20)\n",
    "    calculator.process_file(\n",
    "        input_file=Path(args.input),\n",
    "        output_file=Path(args.output),\n",
    "        start_time=args.start_time,\n",
    "        end_time=args.end_time\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
